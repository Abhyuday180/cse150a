# Import libraries
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator
from pgmpy.inference import VariableElimination

# 1. Data Collection
ticker = "AAPL"
data = yf.download(ticker, start="2010-01-01", end="2023-12-31")
data.to_csv("../data/historical_data.csv")

# 2. Data Exploration
print(f"Number of observations: {len(data)}")
print("Data Description:")
print(data.describe())
data.info()

# Missing Data Check
print("Missing Values:")
print(data.isnull().sum())

# 3. Feature Engineering
# Calculate technical indicators
data['MA_20'] = data['Close'].rolling(20).mean()
data['RSI'] = 100 - (100 / (1 + data['Close'].diff(1).clip(lower=0).rolling(14).mean() / 
                    data['Close'].diff(1).clip(upper=0).abs().rolling(14).mean()))
data['Volatility'] = data['Close'].pct_change().rolling(20).std() * np.sqrt(252)

# Create target variable (Next Day Price Movement)
data['Price_Movement'] = np.where(data['Close'].shift(-1) > data['Close'], 'Up', 'Down')

# Handle missing values
data.dropna(inplace=True)

# 4. Discretization for Bayesian Network
bins = {
    'RSI': [0, 30, 70, 100],
    'Volatility': [0, 0.2, 0.4, np.inf],
    'Volume': [0, data['Volume'].quantile(0.33), data['Volume'].quantile(0.66), np.inf]
}

labels = ['Low', 'Medium', 'High']
data['RSI_Cat'] = pd.cut(data['RSI'], bins=bins['RSI'], labels=labels)
data['Vol_Cat'] = pd.cut(data['Volatility'], bins=bins['Volatility'], labels=labels)
data['Vol_Chg'] = np.sign(data['Volume'].pct_change()).map({1: 'Up', -1: 'Down', 0: 'No Change'})

# 5. Bayesian Network Construction
model = BayesianNetwork([
    ('RSI_Cat', 'Price_Movement'),
    ('Vol_Cat', 'Price_Movement'),
    ('Vol_Chg', 'Price_Movement'),
    ('Price_Movement', 'Action')
])

# Split data into train/test
train_data = data.sample(frac=0.8, random_state=42)
test_data = data.drop(train_data.index)

# Learn CPTs
model.fit(train_data[['RSI_Cat', 'Vol_Cat', 'Vol_Chg', 'Price_Movement', 'Action']],
         estimator=MaximumLikelihoodEstimator)

# 6. Inference
inference = VariableElimination(model)
query = inference.map_query(
    variables=['Action'],
    evidence={
        'RSI_Cat': 'Medium',
        'Vol_Cat': 'High',
        'Vol_Chg': 'Up'
    }
)
print(f"Recommended Action: {query['Action']}")

# 7. Evaluation
# Backtesting
def calculate_returns(model, test_data):
    portfolio = 10000  # Initial investment
    holdings = 0
    
    for idx, row in test_data.iterrows():
        evidence = {
            'RSI_Cat': row['RSI_Cat'],
            'Vol_Cat': row['Vol_Cat'],
            'Vol_Chg': row['Vol_Chg']
        }
        action = inference.map_query(variables=['Action'], evidence=evidence)['Action']
        
        if action == 'Buy' and portfolio > 0:
            holdings += portfolio / row['Close']
            portfolio = 0
        elif action == 'Sell' and holdings > 0:
            portfolio += holdings * row['Close']
            holdings = 0
            
    final_value = portfolio + holdings * test_data.iloc[-1]['Close']
    return final_value

model_returns = calculate_returns(model, test_data)
buy_hold_returns = 10000 * (test_data.iloc[-1]['Close'] / test_data.iloc[0]['Close'])
print(f"Model Returns: ${model_returns:.2f}")
print(f"Buy & Hold Returns: ${buy_hold_returns:.2f}")

